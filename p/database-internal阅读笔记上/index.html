<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="第二章： B-Tree Basics B+ 树是几乎所有基于磁盘的关系型数据库(mysql， pg等)的基础数据结构 B+ 树是Binary Search Tree的衍生， 有跟多的fanout, 所以搜索速度会更快（Log2 -> LogK, 当然在它们的算法复杂度是一致的） B+树的搜索见下图， 是从root根节点一直往下遍历的 数据的增删会触发B+数的split和merge（触发条件就是overflow和underflow） 示意图 B+树（n key， n+1 pointer结构， 当然有些B+树只会在叶子节点存储数据， 然后子节点之间用链表和双向链表来提升查询效率）.\nleaf node的split.\nleaf node的merge\nnon-leaf node的split\nnon-leaf node的merge 上面也看到了， 树的merge和split是比较耗时的操作(以split为例， 在某些场景下是需要一直向上递归的)， 特别在使用磁盘的场景下， 那么减少这种操作（调度）， 或者该表数据大小（压缩）通常会是优化数据库性能的重要方向\n第三章 File Formats 基于磁盘存储的数据库， 它的主要的存储单元是Page, 大小一般是4kb-16kb之间， 基本上一个Page对应一个B-Tree的节点\n"><title>Database Internal阅读笔记(上)</title>
<link rel=canonical href=https://superjcd.github.io/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/><link rel=stylesheet href=/scss/style.min.0304c6baf04e01a8fe70693791cb744d56a3578a3120a8796cefc66825aa39c7.css><meta property='og:title' content="Database Internal阅读笔记(上)"><meta property='og:description' content="第二章： B-Tree Basics B+ 树是几乎所有基于磁盘的关系型数据库(mysql， pg等)的基础数据结构 B+ 树是Binary Search Tree的衍生， 有跟多的fanout, 所以搜索速度会更快（Log2 -> LogK, 当然在它们的算法复杂度是一致的） B+树的搜索见下图， 是从root根节点一直往下遍历的 数据的增删会触发B+数的split和merge（触发条件就是overflow和underflow） 示意图 B+树（n key， n+1 pointer结构， 当然有些B+树只会在叶子节点存储数据， 然后子节点之间用链表和双向链表来提升查询效率）.\nleaf node的split.\nleaf node的merge\nnon-leaf node的split\nnon-leaf node的merge 上面也看到了， 树的merge和split是比较耗时的操作(以split为例， 在某些场景下是需要一直向上递归的)， 特别在使用磁盘的场景下， 那么减少这种操作（调度）， 或者该表数据大小（压缩）通常会是优化数据库性能的重要方向\n第三章 File Formats 基于磁盘存储的数据库， 它的主要的存储单元是Page, 大小一般是4kb-16kb之间， 基本上一个Page对应一个B-Tree的节点\n"><meta property='og:url' content='https://superjcd.github.io/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/'><meta property='og:site_name' content='superjcd'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2023-12-29T00:00:00+00:00'><meta property='article:modified_time' content='2023-12-29T00:00:00+00:00'><meta name=twitter:title content="Database Internal阅读笔记(上)"><meta name=twitter:description content="第二章： B-Tree Basics B+ 树是几乎所有基于磁盘的关系型数据库(mysql， pg等)的基础数据结构 B+ 树是Binary Search Tree的衍生， 有跟多的fanout, 所以搜索速度会更快（Log2 -> LogK, 当然在它们的算法复杂度是一致的） B+树的搜索见下图， 是从root根节点一直往下遍历的 数据的增删会触发B+数的split和merge（触发条件就是overflow和underflow） 示意图 B+树（n key， n+1 pointer结构， 当然有些B+树只会在叶子节点存储数据， 然后子节点之间用链表和双向链表来提升查询效率）.\nleaf node的split.\nleaf node的merge\nnon-leaf node的split\nnon-leaf node的merge 上面也看到了， 树的merge和split是比较耗时的操作(以split为例， 在某些场景下是需要一直向上递归的)， 特别在使用磁盘的场景下， 那么减少这种操作（调度）， 或者该表数据大小（压缩）通常会是优化数据库性能的重要方向\n第三章 File Formats 基于磁盘存储的数据库， 它的主要的存储单元是Page, 大小一般是4kb-16kb之间， 基本上一个Page对应一个B-Tree的节点\n"><link rel="shortcut icon" href=/favicon.ico></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu12125167938935615648.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🍥</span></figure><div class=site-meta><h1 class=site-name><a href=/>superjcd</a></h1><h2 class=site-description></h2></div></header><ol class=menu-social><li><a href=https://github.com/superjcd target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#第二章-b-tree-basics>第二章： B-Tree Basics</a><ol><li><ol><li><a href=#示意图>示意图</a></li></ol></li></ol></li><li><a href=#第三章-file-formats>第三章 File Formats</a><ol><li><a href=#原始的page结构>原始的Page结构</a></li><li><a href=#slotted-page>slotted page</a></li><li><a href=#cell>Cell</a></li><li><a href=#cell的结构>Cell的结构</a></li></ol></li><li><a href=#第四章-implementing-b-trees>第四章 Implementing B-Trees</a><ol><li><a href=#page-header>Page Header</a></li><li><a href=#overflow-pages>Overflow pages</a></li><li><a href=#二分查找在页面中应用>二分查找在页面中应用</a></li><li><a href=#页的split和merge的传播>页的Split和Merge的传播</a></li><li><a href=#rebalancing>Rebalancing</a></li><li><a href=#right-only-appends>Right-only appends</a></li><li><a href=#压缩>压缩</a></li></ol></li><li><a href=#第五章-transaction-processing-and-recovery>第五章 Transaction Processing and Recovery</a><ol><li><a href=#buffer-managment>Buffer managment</a></li><li><a href=#缓存页淘汰机制>缓存页淘汰机制</a></li><li><a href=#数据库日志>数据库日志</a></li><li><a href=#并发控制>并发控制</a></li><li><a href=#3种并发控制流派>3种并发控制流派</a><ol><li><a href=#occ>OCC</a></li><li><a href=#mvcc>MVCC</a></li><li><a href=#pcc>PCC</a></li></ol></li><li><a href=#锁>锁</a><ol><li><a href=#死锁deadlock>死锁Deadlock</a></li><li><a href=#latches>Latches</a></li></ol></li></ol></li><li><a href=#第六章-b-tree-variants>第六章 B-Tree Variants</a><ol><li><a href=#copy-on-write-b-tree>Copy-on-write B-Tree</a></li><li><a href=#lazy--b-trees>Lazy B-Trees</a></li><li><a href=#fd-tree>FD-Tree</a></li></ol></li><li><a href=#第七章>第七章</a><ol><li><a href=#lsm的构成>LSM的构成</a></li><li><a href=#lsm中的更新和删除>LSM中的更新和删除</a></li><li><a href=#lsm中的merge操作>LSM中的merge操作</a></li><li><a href=#lsm中的压缩compact>LSM中的压缩(compact)</a></li><li><a href=#lsm的读写空间放大>LSM的读/写/空间放大</a></li><li><a href=#lsm-实现细节>LSM 实现细节</a><ol><li><a href=#sstablesorted-string-table>SSTable(sorted string table)</a></li><li><a href=#bloom-filter>Bloom filter</a></li><li><a href=#skiplist>Skiplist</a></li></ol></li><li><a href=#unordered-lsm-storage>Unordered LSM Storage</a><ol><li><a href=#bitcask>Bitcask</a></li><li><a href=#wisckey>Wisckey</a></li></ol></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/>数据库</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/>Database Internal阅读笔记(上)</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Dec 29, 2023</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>4 minute read</time></div></footer></div></header><section class=article-content><h2 id=第二章-b-tree-basics>第二章： B-Tree Basics</h2><ul><li>B+ 树是几乎所有基于磁盘的关系型数据库(mysql， pg等)的基础数据结构</li><li>B+ 树是Binary Search Tree的衍生， 有跟多的fanout, 所以搜索速度会更快（Log2 -> LogK, 当然在它们的算法复杂度是一致的）</li><li>B+树的搜索见下图， 是从root根节点一直往下遍历的</li><li>数据的增删会触发B+数的split和merge（触发条件就是overflow和underflow）</li></ul><h4 id=示意图>示意图</h4><p>B+树（n key， n+1 pointer结构， 当然有些B+树只会在叶子节点存储数据， 然后子节点之间用链表和双向链表来提升查询效率）.</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/1.png width=532 height=151 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/1_hu11496292715019633274.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/1_hu14933288381283139119.png 1024w" loading=lazy class=gallery-image data-flex-grow=352 data-flex-basis=845px></p><p>leaf node的split.</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/2.png width=674 height=206 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/2_hu16048913461160528288.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/2_hu15129793064902286847.png 1024w" loading=lazy class=gallery-image data-flex-grow=327 data-flex-basis=785px></p><p>leaf node的merge</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/3.png width=614 height=197 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/3_hu15680180638441770598.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/3_hu8146204659701067482.png 1024w" loading=lazy class=gallery-image data-flex-grow=311 data-flex-basis=748px></p><p>non-leaf node的split</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/4.png width=684 height=229 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/4_hu903176938407582279.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/4_hu225077400272659496.png 1024w" loading=lazy class=gallery-image data-flex-grow=298 data-flex-basis=716px></p><p>non-leaf node的merge
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/5.png width=677 height=246 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/5_hu11568399917259774228.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/5_hu7008973578993771967.png 1024w" loading=lazy class=gallery-image data-flex-grow=275 data-flex-basis=660px></p><p>上面也看到了， 树的merge和split是比较耗时的操作(以split为例， 在某些场景下是需要一直向上递归的)， 特别在使用磁盘的场景下， 那么减少这种操作（调度）， 或者该表数据大小（压缩）通常会是优化数据库性能的重要方向</p><h2 id=第三章-file-formats>第三章 File Formats</h2><p>基于磁盘存储的数据库， 它的主要的存储单元是Page, 大小一般是4kb-16kb之间， 基本上一个Page对应一个B-Tree的节点</p><h3 id=原始的page结构>原始的Page结构</h3><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/6.png width=642 height=84 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/6_hu5428297086272304495.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/6_hu12019344167207151415.png 1024w" loading=lazy class=gallery-image data-flex-grow=764 data-flex-basis=1834px></p><ul><li>p： 指针， 指向子节点</li><li>k: key</li><li>v： value</li></ul><p>这种结构非常适合用来存储大小固定的数据， 比如char(13)来存储电话号码(那么所有电话号码都是同样长度的， 这种方式的存储和查找非常的便利)
但是这种方式最大的问题是不好存储存储可变长度的数据， 比如string或者text</p><h3 id=slotted-page>slotted page</h3><p>现代数据库的page结构， 主要采用的是slotted page的形式：
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/7.png width=458 height=280 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/7_hu12346393113962113822.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/7_hu9985965968662141495.png 1024w" loading=lazy class=gallery-image data-flex-grow=163 data-flex-basis=392px><br>好处就是解决了原始Page结构不好存储可变长度记录的问题， 同时支持在数据被删除的时候进行更好的再利用（下面会提及）</p><h3 id=cell>Cell</h3><p>cell存储各种类型的数据，它在Slotted Page中的插入方式是从尾部往前插入， 然后在Header中的Poitner会依次保留各个cell的offet信息</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/8.png width=628 height=140 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/8_hu11445287324942386616.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/8_hu12426533443688908740.png 1024w" loading=lazy class=gallery-image data-flex-grow=448 data-flex-basis=1076px></p><blockquote><p>为什么采用这样的插入顺序其实也很好理解， 如果直接从左至右， 每次有一个新的cell, 那么原来存储在最左侧（紧挨着Header）的cell， 由于Header变化了， 它也需要相应地右移， 而从尾部向前则不需要</p></blockquote><p>当然如果要保持Offset的逻辑顺序(比如根据Cell数据的字母序)， 我们可以调整Offset的位置
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/9.png width=640 height=156 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/9_hu8837436741558694158.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/9_hu15834357353017269192.png 1024w" loading=lazy class=gallery-image data-flex-grow=410 data-flex-basis=984px></p><blockquote><p>插入顺序： Tom -> Lesile -> Ron， Offsets的顺序则是Lesile -> Ron -> Tom</p></blockquote><p>前面提到了， Slotted Page在空间再利用（reclaim space， 利用被删除的数据）的高效性， 以sqlite db为例， 数据库会维持一份可以用space的指针列表.
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/10.png width=663 height=210 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/10_hu13441783873922228685.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/10_hu9216312680131979259.png 1024w" loading=lazy class=gallery-image data-flex-grow=315 data-flex-basis=757px><br>当要插入新的数据的时候， 会使用First fit或者Best fit算法去找到哪一块空间最最适合插入新数据</p><blockquote><p>First fit: 找到第一块可以容纳新数据的space
Best fit：找到浪费最小的space(就是space和新插入数据大小的差值最小)
从空间利用率上Best fit会更好，当然First fit速度明显会更快</p></blockquote><p>假设， 没有办法找到任意一块能够容纳新数据的空白space， 并且我的空白space总和又大于新数据， 那这个时候就需要进行去碎片化(defragmenting)</p><h3 id=cell的结构>Cell的结构</h3><p>cell有两种， 第一种叫做Key Cell， 主要用来存储key。第二种是Key-Value Cell, 就是同时用来存储key和vlaue的， 一个page上面， 通常是这有这两种key中的任意一种的(因为两种key的结构略有不同， 所以从效率角度， 肯定是存储一种类型的会更好).</p><p>Key Cell结构：</p><ul><li>cell type</li><li>key size</li><li>child page id</li><li>key bytes</li></ul><p>Key-Value Cell结构:</p><ul><li>cell type</li><li>key size</li><li>value size</li><li>key bytes</li><li>Data record bytes(也就是value bytes)</li></ul><h2 id=第四章-implementing-b-trees>第四章 Implementing B-Trees</h2><h3 id=page-header>Page Header</h3><p>page header会存储一些和page相关的元信息， 除了上前面提到的cell offsets, 还会有诸如：</p><ul><li>Magic numbers</li><li>sibling links</li><li>rightmost pointers</li><li>node high key</li></ul><p>magic numbers是会存储在Page上的的特定位置的二进制的值， 比如存储第51 ， 47， 41， 45位的值， 目的是为了验证page有没有被污染， 只要在读数据的时候， 比较一下这几位的实际值和存储在header中的值是否一样即可
一般来说每个node， 会存储n个key以及n+1 pointer指向这个node的子节点， 这个第n个key经常会被存储在page header
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/11.png width=699 height=237 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/11_hu16097888266148504105.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/11_hu1859240776017745930.png 1024w" loading=lazy class=gallery-image data-flex-grow=294 data-flex-basis=707px></p><p>有时候， 这种方式会有一种变体就是key会饿pointer的数量对齐：
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/12.png width=298 height=184 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/12_hu5296876375901662597.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/12_hu17008141340834417729.png 1024w" loading=lazy class=gallery-image data-flex-grow=161 data-flex-basis=388px><br>上面的K3就是high key</p><h3 id=overflow-pages>Overflow pages</h3><p>通常page的size是固定的， 在4-16kb之间， 过大的size不可避免的会照成空间的浪费。 但是page size的固定话， 当可变长的数据过大的时候，我们就需要有一个扩展的页去存储溢出的数据, 这些页就被称为overflow page.</p><blockquote><p>说到底， 磁盘的load reload的开销过大才需要固定size的page， 以及这种overflow page， 如果是内存， 之间原来的size 按比例扩容就好了</p></blockquote><p>page header会保留指向这些overflow page的指针（overflow page也需要保留指向原始页面的指针）
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/13.png width=425 height=367 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/13_hu15914841279285001264.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/13_hu5818170485353002403.png 1024w" loading=lazy class=gallery-image data-flex-grow=115 data-flex-basis=277px><br>一般来说说， 一个page只会指向单一的overflow page， 如果还是放不下， 那么可以继续从overlow page出发链接新的overflow page</p><h3 id=二分查找在页面中应用>二分查找在页面中应用</h3><p>由于page header中可以以逻辑顺序保留cell的offsets， 那么我们完全可以对这些offset进行二分查找：
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/14.png width=666 height=254 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/14_hu4636528305755054932.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/14_hu3022970279502262825.png 1024w" loading=lazy class=gallery-image data-flex-grow=262 data-flex-basis=629px><br>具体步骤就是， 现取这些offsets中最中间的那个， 然后找到对应的cell， 比较和查找键的大小来决定二分查找的方向是往左还是往右</p><h3 id=页的split和merge的传播>页的Split和Merge的传播</h3><p>随着数据的插入和删除， B树的节点需要进行相应的拆分 & 合并， 这意味着子节点的父节点以也会发生变化， 而且这种变化通常是一层层向上传播的。有没有一种高效的算法去更新这种变化 ， 其中一种就是Breadcrums（面包屑）， 这个算法的名称其实很形象地指出了它的实现方式：
我们查找新的插入节点， 一定是从根节点之上而下的， 如果我们记录了这个path的话， 那么将其逆序， 不就找到了每个子节点的父节点嘛？
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/15.png width=608 height=454 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/15_hu10514125994058762311.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/15_hu16135562310550821172.png 1024w" loading=lazy class=gallery-image data-flex-grow=133 data-flex-basis=321px></p><blockquote><p>比如我们要插入一个大于37的数值， 查找路径入上入所示， Breadcrumbs记录了每个insertion point的offset。 Breadcumbs的实现一般是stack</p></blockquote><h3 id=rebalancing>Rebalancing</h3><p>通常来讲， 树的再平衡会涉及到大量的split和merge， 进而影响数据库性能。所以数据库通常会延迟split和merge， 并使用一种相对开销较少的方式去实现reblancing &ndash; 平衡邻居节点之间的数据， 把有较多数据的节点的数据搬到隔壁的节点， 从而避免节点之间的split和merge</p><h3 id=right-only-appends>Right-only appends</h3><p>很多场景下 ， 数据库都有一个自增的键比如一个自增的id， 如果还是采用常规的自上而下的查找方式是纯粹的浪费时间。
Postgresql等数据库， 会直接比较插入的key的值和最右页（存储最大数据的page）的第一个key进行比较， 如果查要插入的key的值更大且该页仍有足够空间， 那么就直接把数据插入到这个最右页上， 避免了自上而下的查找（计算复杂度变化： LogN -> 常数时间，改进很大），这种方式也叫fast path</p><h3 id=压缩>压缩</h3><p>数据的压缩会牵涉到一个很重要的指标： 压缩率:</p><ul><li>更高的压缩率意味着更好的空间利用率</li><li>同时意味着， 更高的时间复杂度， 因为解压缩会消耗大量的cpu资源</li></ul><p>很明显， 这里有一个非常重要的tradeoff : 空间vs时间</p><p>另外通常来讲， 我们不会再文件层级去压缩数据， 只会在page级别， 很明显前者会影响查询效率。</p><p>另外压缩的方式除了和page绑定在一起， 也可以作为一种插件的形式进行， 和page的管理进行解耦（比如对整个column的数据进行压缩， 其实列式数据就是这么做的）</p><h2 id=第五章-transaction-processing-and-recovery>第五章 Transaction Processing and Recovery</h2><h3 id=buffer-managment>Buffer managment</h3><p>类似于IO系统， 数据库也会使用类似缓存页(page cache)的概念来管理访问数据的缓存。</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/16.png width=706 height=249 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/16_hu2406060134070999495.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/16_hu5194839600468494596.png 1024w" loading=lazy class=gallery-image data-flex-grow=283 data-flex-basis=680px><br>上图展示了B+树的节点Page在缓存池以及在磁盘上的对应关系。
Page cache机制的包括：</p><ul><li>将数据保留在内存</li><li>如果要的Page在内存中， 直接返回缓存页</li><li>如果需要的Page不再内存中， 且Buffer pool足够大， 会将该页存储在缓存池（page in）</li><li>如果没有足够空间来存储新的缓存页， 就需要运行某种机制淘汰（eviction）一部分缓存页（比如使用LFU, LRU， CLOCK等算法）， 然后当缓存页被淘汰的时候， 会写道磁盘以保证数据的一致性</li></ul><p>缓存页可以看作是数据请求和磁盘之间的中间层， 除了数据的读取， 数据的变更其实也是优先发生在这个中间层， 而不是直接写入到磁盘， 在内存中的缓存页数据被修改的时候， 这个时候这个页面就会被标识脏页(dirty page), 标识和磁盘数据不同步。
当然dirty page中的数据最后一定会被写入到磁盘， 为了保证这个过程不会出现纰漏（比如由于停电等原因， 改变的数据没有被同步到磁盘， 进而影响了数据库的ACID保证）， 通常会使用一种叫做WAL（write ahead log, 预写日志）的机制来保证数据的一致性</p><blockquote><p>WAL其实就是一系列的数据变更记录， 通常会在事务成功发生之后（commit）被保存在磁盘， 由于很多条记录其实可以被合并成一条， 比如对一个账户A增加1000， 记录一次， 减少1000再记录一次， 那这两条记录就可以被抵消掉， 另外WAL虽然是基于磁盘的， 但是它是顺序写入而不是随机写入 ，所以它的写入速度也是很快的</p></blockquote><h3 id=缓存页淘汰机制>缓存页淘汰机制</h3><p>常见的有LRU（Least Recently Used）, LFU(Least Freaquntly Used)，CLOCK。 LRU会比较侧重一个时效性， 越是被最近访问的Page原容易被缓存（最新访问的page会被放到链表的尾部， 然后链表头部的数据会被淘汰掉）， 在实践中(不只是数据库领域)， LFU通常会更常用一点， LFU相较于LRU会更侧重Page的访问频率， 低频的页会被有限淘汰</p><p>Clock机制</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/17.png width=221 height=226 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/17_hu1550703330011799714.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/17_hu5380227924730648811.png 1024w" loading=lazy class=gallery-image data-flex-grow=97 data-flex-basis=234px><br>clcok机制就是用一种环形链表将所有的Page组织在一起， 当页面被访问， 它就会被设置为1（上图灰色所示）， 当后台运行淘汰任务的时候， &lsquo;指针&rsquo;随机指向一个Page, 如果它是0（最近没有被访问）就会被淘汰掉， 也就是说它和LRU相比， 增加了一个随机性
如果对clock机制进行一定的改造， 把1和0的bit标识改成数值(被引用次数)， 然后当一个缓存页码，每次访问的时候， 它对应的数值就会+1， 淘汰指针转动的时候则-1, 如果是0就该页就会被淘汰， 那么它就被改造成了类似LFU的模式</p><h3 id=数据库日志>数据库日志</h3><p>我们在前面的Buffer management的时候提到过淘汰缓存页时，就需要将数据写入磁盘， 为了保证数据的一致性， 需要用到WAL。WAL本质上是一种日志， 在某些数据库还会按照功能区分为： redo日志， undo日志， 简单来讲redo是为了数据恢复的， undo是为了将已经保存到了数据库的数据撤回的。
然后日志的类型会有两种， 一种是物理日志(pysical log)， 日志文件将会将数据直接记录在日志中； 另一种是逻辑日志(logical log)， 逻辑日志只记录了操作而没有数据。因为物理日志有数据， 所以通常会被用在redo阶段， 这样数据恢复会更快， 逻辑日志则会被用在undo阶段
这里我们说之所以会需要undo数据（写入了磁盘的数据并没有完成commit）， 写入磁盘的操作允许被发生在commit之后， 这种数据库策略通常被称为no-force/steal 策略，相对的force/no-steal则会要求数据在commit之前写入数据， 所以force策略下， 数据库在恢复的时候只要关心redo日志就好， 因为根据策略， 但凡是日志中显示commit是先需要写入磁盘的。
但是为啥数据库还会允许no-force的这种发生写盘操作在commit之后的操作存在呢， 原因也很简单， 提升tansaction的速度。
最后， 关于数据库日志还有一个概念是checkpoint， 顾名思义就是日志的记录点， 每个checkpoint都有一个对应的LSN（log sequence number, 单调增）， 目的是为了替身redo和undo效率的， 有了checkpont我自要从上一个LSN进行数据恢复操作就好了， 而不需要每次把所有脏页进行写盘</p><h3 id=并发控制>并发控制</h3><p>数据库中由于并发引起的读写异常， 其实和隔离级别（isolation level）有关， 常见的隔离级别有(从低到高)：</p><ul><li>Read Uncomiited, 允许事务并发读取别的没有提交的事务， 这种隔离级别下， 很容易导致脏读</li><li>Read Commited, 一个事务只能去读已经被提交了记录。但是这种隔离级别依然无法保证对相同数据同时读取（已经都是提交了的）， 能观察到相同的数据； 因为有可能在数据读取的过程中， 数据发生了改变， 导致并非读看到不一样结果</li><li>Reapetable Read，所以在上一个隔离级别的基础上， 这个级别能保证 对数据的同时访问， 获取相同的结果</li><li>Serializable， 最强的隔离级别， 意味着所有的事务都是按照时序展开， 会有最强的数据一致性保证，也就意味着最糟糕的并发性能</li></ul><p>下图展示了各种隔离级别对应的读写异常的可能性， 可以看到Seriaizable基本是绝缘所有并发引起的读写异常， 当然代价就是牺牲并发.</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/18.png width=435 height=105 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/18_hu11750801711644344439.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/18_hu17448313141079290095.png 1024w" loading=lazy class=gallery-image data-flex-grow=414 data-flex-basis=994px></p><h3 id=3种并发控制流派>3种并发控制流派</h3><p>有三种常见的并发控制流派：</p><ul><li>OCC， Optimistic concurrency control</li><li>MVCC, Multiversion concurency control</li><li>PCC, Pessimistic concurency control</li></ul><h4 id=occ>OCC</h4><p>把事务分成三个阶段：</p><ul><li>Read phase</li><li>Validation phase</li><li>Write phase</li></ul><p>在第一阶段， 会把所有并发的事务的dependency写入到read set（不改变数据库状态的操作）和write set中（会有副作用， 会改变数据库操作）
第二阶段， 就是根据read set和write set中的操作， 特别是有相交（冲突）部分的操作， 对那些可能会受影响的事务， 比如一个读相关的事务， 它的数据正在被另一个事务写， 那么这个读的事务就会被终止， 不然会导致脏读
第三阶段， 当然， 如果在第二阶段中没有检查到冲突，就可以顺利的提交</p><h4 id=mvcc>MVCC</h4><p>简单来讲就是给所有的事务一个单调增的事务ID， MVCC通常不会阻止你去取旧的数据， 但是通常会确保在系统里面只存在一个没有提交的事务版本（version）</p><blockquote><p>所以这种方式应该会产生脏读， 但是因为只允许耽搁未提交事务版本， 所以最终一致性还是可以保证的</p></blockquote><h4 id=pcc>PCC</h4><p>PCC通常会和锁一起出现， 当然也有不需要要锁的实现方式， 其中最简单的PCC实现方式就是基于时间戳， 通常会有两个时间戳：</p><ul><li>max_read_timestamp</li><li>max_write_timestamp</li></ul><p>除了写操作被允许可以在max_write_timestamp之前被执行， 其他的操作不能在另一个读写操作的最大timestamp执行
相对而言， 基于锁的实现方式会更加流行</p><h3 id=锁>锁</h3><h4 id=死锁deadlock>死锁Deadlock</h4><p>死锁会发生在两个进程或者说事务都在等待彼此去释放锁， 有点类似于循环引用的问题(A模块要导入b， b模块也要导入A)</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/19.png width=352 height=194 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/19_hu8443251899596572147.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/19_hu12217765076026390667.png 1024w" loading=lazy class=gallery-image data-flex-grow=181 data-flex-basis=435px>
怎么去解决死锁呢， 当然一种简单的方式就是给登台加上一个timeout时间， 这样就可以避免陷入无限等待。
还有方式就是让系统去识别这种可能造成死锁的状态， 也就是一个后台程序去检查事务直接存在不存在上面的waits-for graph， 如果存在就停掉其中的一个事务。</p><h4 id=latches>Latches</h4><p>Latch也是锁， 但是和lock不一样的点在于， lock更多的是一种更高高级的抽象概念，远离数据库内核的存储结构。 而latch， 则是更接近数据存储结构的， 它是用来解决Page层面也就是更底层的竞争问题的。
我们可你是不希望一个Page在被更高或者说要被split和merge的时候被访问， 因为这样很可能会导致我们前面提到的读异常， 所以需要Latch在更底层帮我们去控制竞争。
但是由于B树的特殊性， 我们知道子节点的merge和split很有可能会向上传播到root（当然只是可能， 并不是绝对）， 那么仅仅在某个页面上进行竞争控制是不够的。一种相对朴素的实现方法， 就是对整个访问路径上的所有Page加上Latch, 淡然这种肯定胡牺牲性能。
所以更常用的方式， 是使用Latch crabbing的一种方式：这种方式它不会一直保留整个访问路径上的page上的锁， 而是从根节点开始， 不断向下， 只要当前节点不是full的状态(意味着大概率不会被至下而上的split merge影响） 我们就打开这个锁， 所以在特点的时间节点， Latch crabing只会给很小一部分page加锁</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/20.png width=471 height=515 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/20_hu2416453500191070531.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/20_hu7099331628690967540.png 1024w" loading=lazy alt=imgae.png class=gallery-image data-flex-grow=91 data-flex-basis=219px></p><h2 id=第六章-b-tree-variants>第六章 B-Tree Variants</h2><p>如何提升基于B-Tree存储结构的数据库读写效率呢， 主要的改进方向其实就是->减少访问硬盘的次数和时间（特别是减少小批量的写入）, 再这种所提到的所有改进方法都是围绕这个核心点来的</p><h3 id=copy-on-write-b-tree>Copy-on-write B-Tree</h3><p>传统的B-树， 一般底层使用latch来解决再并发时的问题， copy-on-write直接舍弃了这种方式，直接复制会被修改的page(也就是脏页)，同时不会阻止用户访问旧数据。
当新的Page结构被构建完成的时候， 更新原有B-Tree的指针， 指向新的Page即可:</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/21.png width=470 height=172 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/21_hu17143619289894138059.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/21_hu6068043162215445689.png 1024w" loading=lazy class=gallery-image data-flex-grow=273 data-flex-basis=655px><br>这种方式无疑是增加了磁盘空间的消耗， 好处有:</p><ul><li>避免了latch的使用</li><li>读写互不影响</li><li>数据库系统也不会处在一种被污染的状态(无非就是新的页的pointer没有替换掉老的， 但是原来的树结构和数据还是完整的， 只是过时了而已)</li></ul><h3 id=lazy--b-trees>Lazy B-Trees</h3><p>lazy B-Tree主要时通过结合内存或者说优化page cache的方式， 减少磁盘访问。以mongodb种使用的默认存储引擎WiredTiger为例（简称WT）
WT首先会保留一份磁盘种的树结构， 当然只是Index， 并没有具体的数据。当某个page首次被读取的时候，这个page的内容会复制到到对应的update buffers， 用户可以被允许直接访问update buffers中的数据（还没被写入磁盘）， 后天程序会周期性地将update buffer数据写入到磁盘取覆盖原来的Page， 如果覆盖页的size大于原来的size， 它会拆分成多个页
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/22.png width=667 height=419 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/22_hu7276162576927427713.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/22_hu10032017794182745933.png 1024w" loading=lazy class=gallery-image data-flex-grow=159 data-flex-basis=382px></p><h3 id=fd-tree>FD-Tree</h3><p>FD-Tree结合了B+tree和LSM树的特征（核心特点就是从随机磁盘写入->顺序写入）。
它在最顶层（也称为L0）会维护一颗树， L0在无法存储更多key的时候， 会把key融合到下一层（不是所有key， 而是特殊的key， 也被称为fence, 这些fence会有一个指向下一层的Pointer
<img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/23.png width=672 height=224 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/23_hu3766607018793258339.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/23_hu280856478935752144.png 1024w" loading=lazy class=gallery-image data-flex-grow=300 data-flex-basis=720px><br>上图是FD-Tree的一个样例，可以看到最的顶层（L0）是一个树结构， 然后灰色的方框就是特殊的Index entry， 指向下一level的array的相同entry, 但是fence也有开那个中类型， 一种是external， 这种类型会被merge到下一层（也就是下一层会有一个相同的entry）， 另外一种是internal（比如上面的88）， 你会发现它只出现在L1没有出现在L2.
FD-Tree的查找复杂度也是Log数量级</p><h2 id=第七章>第七章</h2><p>前面一章， 对数据库优化方向主要围绕减少磁盘写入开销的来的， 以WiredTiger为例的方法， 都是通过数据的缓存管理来实现上面这目标， 还有一种优化的方向， 就是把耗时的磁盘随机写入操作转化为磁盘的顺序写入， LSM-Tree就是这种思想的集大成者。
LSM-Tree， 全称log structed merge， 这个名字本身就昭示了这种存储结构的特征：</p><ul><li>log structure： 像日志一样只会在磁盘中追加写入(append only)</li><li>merge， 不在磁盘中删改数据， 通过merge来应对不同版本数据的问题</li></ul><p>LSM树由于append only的特征， 所以这种结构是非常适合写多于读的场景（吞吐量ingestion较高的场景）， 另外由于读写在结构上互不影响， 所以不会受类似B-tree的锁机制影响并发性能</p><h3 id=lsm的构成>LSM的构成</h3><ul><li>Memtable(下面两个都算是memetable, 前者接受写， 后者只接受读）， 在内存中</li><li>Current memtable</li><li>Fushing memtable</li><li>On-disk flush target</li><li>Flush tables</li><li>Compacting tables</li><li>Compated tabe</li></ul><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/24.png width=600 height=241 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/24_hu7516303752207364248.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/24_hu15231139590534022483.png 1024w" loading=lazy class=gallery-image data-flex-grow=248 data-flex-basis=597px><br>上图显示了LSM的整个生命周期，其中除了Current Memtable同时支持读写以外， 其他的阶段只支持读数据， 不支持数据的写入
另外有两个要点：</p><ul><li>数据在内存中的时候， 它是排过序的</li><li>数据在被写入磁盘的时候， 也会用的WAL， 防止数据丢失</li><li>当数据被写入磁盘之后， 内存中的数据就会消失， 那么后续相关数据的查询之恶能通过磁盘中的数据获取</li></ul><h3 id=lsm中的更新和删除>LSM中的更新和删除</h3><p>更新的话很简单， 只要写入新的数据就好， 新的数据会在后买你覆盖旧数据，问题在于如何删除数据。由于我们不会直接删除LSM存储在磁盘的数据， 如果一个数据同时存储在Memtable和Disk table的情况下， 我如何在不直接删除Disk table的数据来实现删除呢。 常用的方法就是为这个需要被删除的key设置一个tomestone（墓碑）， 这样在merge的时候，老的数据会被tomestone覆盖掉， 就达到了删除的效果</p><h3 id=lsm中的merge操作>LSM中的merge操作</h3><p>因为数据会被存储在多个磁盘区域， 很有可能多个disk table这间会有数据冲突的问题， 即它们都保有相同key的数据， 所以需要通过merge来解决冲突
整个流程划分为一下三个步骤：</p><ul><li>从不同的迭代器(就是存储在不同区域的磁盘数据， 他们本身是sorted的， 所以可以支持iteration)依次获取数据</li><li>把这些候选值入队（优先队列，可以通过min heap小顶堆来实现)， 最小的那个值放入结果集</li><li>继续从被选择的迭代器中补充数据加入队列</li></ul><p>重复上面的流程， 如果第二个流程遇到key相同的情况， 可以选择通过记录本身携带的timestampe来解决冲突</p><h3 id=lsm中的压缩compact>LSM中的压缩(compact)</h3><p>常用的方法有Leveled compaction和Size-tiered
这里以Leveled 为例， 位于顶层(接近0)的table会将数据不断“下沉”
到下一个level（前提是当前的level放不下更多table了）， 这个过程会对key的范围重合的table进行融合</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/25.png width=579 height=170 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/25_hu10583470682730531731.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/25_hu13307338455303058902.png 1024w" loading=lazy class=gallery-image data-flex-grow=340 data-flex-basis=817px><br>比如level 1 和 Level 2中的阴影部分， 它们key range 重合了， 所以需要融合。 融合的结果就是， 上面的数据， 也就是新的数据在观感上会一点点地“下沉”到下一个level。
另外， 通常来说下一层的Level会保留上一层2倍左右的大小</p><h3 id=lsm的读写空间放大>LSM的读/写/空间放大</h3><p>我们优化数据的目标其实就是解决写放大， 读放大以及空间放大的问题：</p><ul><li>读放大：需要读取多个地址来获取数据, LSM会有这个问题</li><li>写放大： 需要大量的重写操作， B树有这个问题， 在涉及到page层面的数据增删的时候， LSM的compact阶段其实也有</li><li>空间放大： LSM会有冗余数据， 所以这个很明显是有的</li></ul><p>有一种指标RUM conjection（RUM分别代表read，update以及memeory）可以被用来比较及衡量一个数据库引擎的综合性能。我们需要了解的是， 通常来说， 解决上面中的任一一个问题， 都需要付出其他两个点中的1个或2个作为代价， 有点类似于分布式理论中的CAP理论， 你们很难同时拥有所有好处</p><h3 id=lsm-实现细节>LSM 实现细节</h3><h4 id=sstablesorted-string-table>SSTable(sorted string table)</h4><p>LSM树中的table是基于SSTable实现的</p><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/26.png width=749 height=339 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/26_hu11263276291694691962.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/26_hu3896828638660207877.png 1024w" loading=lazy alt=sst.png class=gallery-image data-flex-grow=220 data-flex-basis=530px><br>SST也会用到hash表， 但是是一个稀疏的hash表， 只记录了部分key和它们的位置（offset）， 数据本身是以key和value连续存储在磁盘上的</p><h4 id=bloom-filter>Bloom filter</h4><p>LSM存在的一个性能瓶颈就是读放大， 就是它的数据存储在多个table， 如果存在一个key， 在所有的数据文件中并不存在， 它依然需要取读所有的文件， 从而成为性能瓶颈， 所以可以使用Bloom filter来过滤掉不存在的key， 今儿减少读放大引起的性能问题</p><h4 id=skiplist>Skiplist</h4><p>将文件顺序地存储在内存的一种方式就是使用skiplist</p><h3 id=unordered-lsm-storage>Unordered LSM Storage</h3><p>一一般来说lsm的数据都是以有序地形式被存储的， 当然也有并不是有序形式存储的结构</p><h4 id=bitcask>Bitcask</h4><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/27.png width=526 height=313 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/27_hu1752955340620232179.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/27_hu6532847045990745788.png 1024w" loading=lazy class=gallery-image data-flex-grow=168 data-flex-basis=403px></p><p>bitcask会在内存中保留一份key的最新路径的hash表(Keydir), keydir会在数据库初始话的时候被加载到内存， 所以很自然地会导致初始化时间过长的问题， 同时由于数据是直接被追加到磁盘的， 并不是有序（也没有什么memtable）， 所以bitcask也不支持范围查询（range query)。
但是它的优势也很明显， 首先点查询非常快， 同时写入数据是直接追加的所以写入性能也很好</p><h4 id=wisckey>Wisckey</h4><p><img src=/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/28.png width=600 height=341 srcset="/p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/28_hu11538987639246787095.png 480w, /p/database-internal%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%8A/imgs/28_hu15540042157964144895.png 1024w" loading=lazy class=gallery-image data-flex-grow=175 data-flex-basis=422px></p><p>wisckey会将index和数据记录分开记录（SST， key和value是存储在一起的）， 分别存储在index lsm tree和vlog files。
vlogs files类似bitcask， 是无序地， 顺序增加的日志文件index lsm tree保留了指向vLog的指针， 所以它可以保留了范围查询的优点
它的缺点是， 有序vlog没有关于数据的l生命周期的信息(liveness, 也就是数据是不是仍然是有效的)， 所以在垃圾回收的时候， 必须要遍历左侧的index tree， 增加了复杂度。 传统的lsm， 哪怕是被删除的数据， 也可以在数据压缩阶段被直接覆盖(前面提到的类似墓碑的标记)</p></section><footer class=article-footer><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><div id=gitalk-container></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css><script src=https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js></script><script src=https://cdn.jsdelivr.net/npm/blueimp-md5@2.18.0/js/md5.min.js></script><script>const gitalk=new Gitalk({clientID:"4cde8442733ac793019a",clientSecret:"06b853952b0075feb92709fa5e11392338d176d9",repo:"comments",owner:"superjcd",admin:["superjcd"],distractionFreeMode:!1,id:md5(location.pathname)});(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("gitalk-container").innerHTML="Gitalk comments not available by default when the website is previewed locally.";return}gitalk.render("gitalk-container")})()</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 superjcd</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.26.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>